> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [www.hainiubl.com](http://www.hainiubl.com/topics/76179)

1.kafka 的整体框架[#](#1.kafka的整体框架)
-------------------------------
![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129103051612.png)

首先 kafka 启动以后所有的 broker 都会向 zookeeper 进行注册，
- 在 / brokers/ids 中以列表的形式展示所有的节点，
- 在 / controller 节点中使用独享锁实现 broker 的选举
其中一个broker为主节点。其他的为从节点，选举的根本原则就是谁先来的谁就是主节点


broker0 现在是 controller 节点，
- 他会监听所有的 broker 节点的动态变化，
- 会选举出所有的 topic 的分区副本的主从，这个选举完毕以后，
	- 所有的操作都会指向主分区，不管是生产数据还是消费数据都是主分区在管理，从分区只是同步数据的
- 选举完毕以后将数据上传到 zookeeper 中，记录在 / broker/topics 这个目录中
	- 具体的 topic 信息都会被其他的 broker 节点进行同步过去，多个 broker 都会识别选举出来的主从分区信息

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129104400723.png)


在 zookeeper 中的 ISR（In-Sync Replicas）是指与 leader 节点保持数据同步的副本节点。
- 数据的传输顺序在 ZooKeeper 中通常是按照以下步骤进行的：
- 客户端向 ZooKeeper 集群发送数据请求。
- 请求会首先发送到 leader 节点。
- Leader 节点接收到请求后，将数据更新应用到其本地状态，并将更新的数据同步给 ISR 中的副本节点。
- 一旦大多数 ISR 中的副本节点确认收到了数据更新，ZooKeeper 将此更新视为已提交（committed），然后向客户端发送确认响应。

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129105129450.png)

数据生产和传输都会走主节点，topic 正常对外提供服务

2.kafka 的基础数据结构[#](#2.kafka的基础数据结构)
-----------------------------------

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129105926163.png)

kafka 中的数据存储分为 k-v 两个部分
- 存储的数据都是二进制的，
	- 我们在存储数据的时候要转换为二进制存储，使用的时候读出来也是二进制的，
		- 我们需要人为转换成自己想要的数据类型才能使用，
		- 二进制就不用管具体的存储格式，因为她只是一个暂存的作用
	- 这个和 hbase 的存储及其相似，但是其中的 k 一般我们都不会做任何操作，直接放空值，只放入 value 的值

虽然数据分为 k-v 两个部分，但是不要把它当成 map 集合，相同的 key 的数据 value 不会被去重掉

3.producer 的结构[#](#3.producer的结构)
---------------------------------
![](https://raw.githubusercontent.com/2Lavine/ImgRep/main/img/2024/02/28/202402281324188_13-24-43_13-28-40.png)

producer它由三个部分组成

- serialiazer：序列化器  (required)
	- kafka 中存储的数据是二进制的，所以数据必须经过序列化器进行处理
	- 将用户的数据转换为 byte[] 的工具类，其中 k 和 v 要分别指定
 - partitioner: 分区器 (required)
	 - 主要是控制发送的数据到 topic 的哪个分区中，这个默认也是存在的

 - interceptor：拦截器，(optional)
	- 能拦截到数据，处理完毕以后发送给下游，
	- 它和过滤器不同并不是丢弃数据，而是将数据处理完毕再次发送出去，这个默认是不存在的 


## **record accumulator**
本地缓冲累加器 默认 32M
![](https://raw.githubusercontent.com/2Lavine/ImgRep/main/img/2024/02/28/202402281324188_13-24-43_13-28-40.png)
producer 的数据不能直接发送到 kafka 集群中
- 因为 producer 和 kafka 集群并不在一起，远程发送的数据不是一次发送一条这样太影响发送的速度和性能，所以我们发送都是攒一批数据发一次，

record accumulator 就是一个本地缓冲区，
- producer 将发送的数据放入到缓冲区中
- 另外一个线程会去拉取其中的数据，远程发送给 kafka 集群，
	- 这个异步线程会根据 linger.ms 和 batch-size 进行拉取数据
如果record accumulator中的数据达到 batch-size 或者是 linger.ms 的大小阈值就会拉取数据到 kafka 集群中
- linger.ms 默认为 0
- 这个本地缓冲区不仅仅可以适配两端的效率，还可以批次形式执行任务，增加效率

为什么batch-size 默认 16KB而 accumulator 是32M?
- producer 产生的数据比较快，而 sender 数据比较慢


## **生产者部分的整体流程**
首先 producer 将发送的数据准备好
经过 interceptor 的拦截器进行处理，如果有的话
然后经过序列化器进行转换为相应的 byte[] 
经过 partitioner 分区器分类在本地的 record accumulator 中缓冲 
sender 线程会自动根据 linger.ms 和 batch-size 双指标进行管控，复制数据到 kafka

4.producer 简单代码[#](#4.producer简单代码)
-----------------------------------

引入 maven 依赖
```
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>3.3.2</version>
    </dependency>
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-log4j12</artifactId>
        <version>1.7.30</version>
    </dependency>
    <dependency>
        <groupId>log4j</groupId>
        <artifactId>log4j</artifactId>
        <version>1.2.17</version>
    </dependency>
</dependencies>
```

在 resources 文件中创建 log4j.properties
```
log4j.rootLogger=info,console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.out
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c %M(): %m%n
```

生产者中的设定参数

<table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>bootstrap.servers</td><td>kafka 集群的地址</td></tr><tr><td>key.serializer</td><td>key 的序列化器，这个序列化器必须和 key 的类型匹配</td></tr><tr><td>value.serializer</td><td>value 的序列化器，这个序列化器必须和 value 的类型匹配</td></tr><tr><td>batch.size</td><td>批次拉取大小默认是 16KB</td></tr><tr><td>linger.ms</td><td>拉取的间隔时间默认为 0，没有延迟</td></tr><tr><td>partitioner</td><td>分区器存在默认值</td></tr><tr><td>interceptor</td><td>拦截器选的</td></tr></tbody></table>

全部代码如下

```java
package com.hainiu.kafka;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class Producer1 {
    public static void main(String[] args) {
        Properties pro = new Properties();
		pro.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"nn1:9092");
        //设定集群地址
        pro.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        pro.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        //设定两个序列化器，其中StringSerializer是系统自带的序列化器，要和数据的类型完全一致
        pro.put(ProducerConfig.BATCH_SIZE_CONFIG, 16*1024);
        //batch-size默认是16KB，参数的单位是byte
        pro.put(ProducerConfig.LINGER_MS_CONFIG, 0);
        //默认等待批次时长是0
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(pro);
        ProducerRecord<String, String> record = new ProducerRecord<>("topic_a", "this is hainiu");
        //发送数据的时候有kv两个部分，但是一般k我们什么都不放，只放value的值
        producer.send(record);
        producer.close();
    }
}
```


5.producer 端的回调和 ack[#](#5.producer端的回调和ack)
--------------------------------------------

![](https://raw.githubusercontent.com/2Lavine/ImgRep/main/img/2024/02/28/image-20230129124450428_13-58-16.png)

sender 线程会异步的拉取数据到 kafka 集群中
-  sender 有一个回调函数来确定sender 线程拉取并且复制 kafka 集群是否成功，
	- 回调函数指的是作为参数的一个函数
	- sender 发送完成之后会调用这个回调函数
- 如果我们在 producer 中设定了 retries 开关，那么失败以后 sender 线程还会多次重新复制尝试拉取数据
	- 失败尝试和 producer 端没有任何关系，producer 端只是将数据放入到本地累加器中而已，失败尝试是由 sender 线程重新尝试的

ack 的级别：
- ack = 0 ；sender 线程认为拉取过去的数据 kafka 一定会收到
- ack = 1 ; sender 线程拉取过去的数据 leader 节点接收到，并且存储到自己的本地
- ack = -1 ; sender 线程拉取数据，leader 节点收到存储到本地，所有 follower 节点全部都接收到并且存储到本地
	- 或者设置为all
综上所述 ack = -1 的级别是数据稳定性最高的，因为能够保证数据全部都同步完毕再返回给 sender 线程

带有确认应答的代码：
- 其中回调函数中的 metadata 对象可以知道发送数据到哪里了，exception 用于区分是不是本条数据发送成功

但是这个回调函数不能做出任何的反馈操作，只能起到通知的作用

```java
producer.send(record, new Callback() {
            //发送方法中增加回调代码
            @Override
	public void onCompletion(RecordMetadata metadata, Exception exception) {
		//metadata中包含所有的发送数据的元数据信息
		//哪个topic的那个分区的第几个数据
		String topic = metadata.topic();
		int partition = metadata.partition();
		long offset = metadata.offset();
		if(exception == null ){
			System.out.println("success"+" "+topic+" "+partition+" "+offset);
		}else{
			System.out.println("fail"+" "+topic+" "+partition+" "+offset);
    }
}
```

6 自定义拦截器[#](#6.自定义拦截器)
-----------------------
interceptor 是拦截器，可以拦截到发送到 kafka 中的数据进行二次处理，它是 producer 组成部分的第一个组件
```java
public static class MyInterceptor implements ProducerInterceptor<String,String>{
        @Override
        public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {return null;}
        @Override
        public void onAcknowledgement(RecordMetadata metadata, Exception exception) {}
        @Override
        public void close() {}
        @Override
        public void configure(Map<String, ?> configs) {}
    }
```

实现拦截器需要实现 ProducerInterceptor 这个接口，其中的泛型要和 producer 端发送的数据的类型一致
- onSend 方法是最主要的方法用户拦截数据并且处理完毕发送  
- onAcknowledgement 获取确认应答的方法，这个方法和 producer 端的差不多，只能知道结果通知  
- close 是执行完毕拦截器最后执行的方法  
- configure 方法是用于获取配置文件信息的方法

我们拦截器的实现基于场景是获取到 producer 端的数据然后给数据加上时间戳
整体代码如下：
```java
pro.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,MyInterceptor.class.getName());
```


拦截器一般很少人为定义，比如一般 producer 在生产环境中都是有 flume 替代，一般 flume 会设定自己的时间戳拦截器，指定数据采集时间，相比 producer 更加方便实用

7.自定义序列化器[#](#7.自定义序列化器)
-------------------------

kafka 中的数据存储是二进制的 byte 数组形式，所以我们在存储数据的时候要使用序列化器进行数据的转换，序列化器的结构要和存储数据的 kv 的类型一致
- 正常send 的数据打印是没有 value 值的

比如我们要实现系统的 String 类型序列化器
**整体代码如下**
```java

    public static class MyStringSerializer implements Serializer<String>{
        @Override
        public byte[] serialize(String topic, String data) {
            return data.getBytes(StandardCharsets.UTF_8);
        }
    }
```

序列化对象整体
```java
    对象序列化
			byteOS =new ByteArrayOutputStream();
			objectOS = new ObjectOutputStream(byteOS);
			objectOS.writeObject(data);
			return byteOS.toByteArray();
```

ByteArrayOutputStream 对象 byteOS，
- 字节数组输出流，用于将串行化后的字节流写入到内存中的字节数组中。
ObjectOutputStream 对象 objectOS，
- 它是一个对象输出流，用于将对象串行化并写入到 byteOS 中。
 byteOS.toByteArray() 获取 byteOS 中的字节数组，即串行化后的对象表示形式，然后将其返回。

内容序列化
整体代码如下：
```java
    public static class StudentSeria implements Serializer<Student> {

        @Override
        public byte[] serialize(String topic, Student data) {
            String line =data.getId()+" "+data.getName()+" "+data.getAge();
            //获取student对象中的所有数据信息
            return line.getBytes(Charset.forName("utf-8"));
            //转换为byte数组返回
        }
    }
}
```

shell 消费者端打印的结果信息