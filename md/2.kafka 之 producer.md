

8 分区器[#](#8.分区器)
-----------------
首先在 kafka 存储数据的时候 topic 中的数据是分为多个分区进行存储的
好的分区器可以让数据尽量均匀的分布到不同的机器节点，数据更加均匀
- 可以从图中看到在本地的累加器中进行存储缓存时就已经进行了分区
- topic 设定分区的好处是可以进行分布式存储和分布式管理
![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129142514403.png)

kafka 的分区规则是如何实现的呢？
```
ProducerRecord<String, Student> record = new ProducerRecord<>("topic_a", student);
producer.send(record);
```
kafka 的生产者数据发送是通过上面的方法实现的
首先要构造一个 ProducerRecord 对象，然后通过 producer.send 来进行发送数据
其中 ProducerRecord 对象的构造器种类分为以下几种

```
new ProducerRecord(topic,partition,k,v);
//指定分区直接发送数据到相应分区中
new ProducerRecord(topic,k,v);
//没有指定分区就按照k的hashcode发送到不同分区
new ProducerRecord(topic,v);
//如果k和partition都没有指定就使用粘性分区
```

粘性分区
- 将一个分区放入数据，一旦满了以后才会改变分区，
- 如果满足 batch-size 或者 linger.ms 就会触发应用执行，将数据复制到 kafka 中，并且再次随机到其他分区
- 粘性分区规则使用主要是为了让每次复制数据更加快捷方便都赋值到一个分区中


9 自定义分区器[#](#9.自定义分区器)
-----------------------

以上规则的演示全部都是按照默认分区器的规则 DefaultPartitioner

我们可以人为定义分区器的规则来替换原生分区器的规则，因为在很多时候默认分区器的规则都不适用于业务场景

**程序背景：**

使用 producer 采集本地数据并且发送到不同的分区中，按照每个专业的类别将数据分发到不同的分区


# 首先创建topic名称为teacher，设定分区数量为spark和java两个分区
kafka-topics.sh --bootstrap-server nn1:9092 --create --topic teacher --partitions 6 --replication-factor 2
# 创建一个data/teacher.txt 放入老师的访问数据，然后分类发送
实现思路就是采集数据然后将数据按照专业分类，分别发送到不同的分区中，自定分区器逻辑
```java
public static class MyPartitioner implements Partitioner{

        @Override
        public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
            return 0;
        }

        @Override
        public void close() {

        }

        @Override
        public void configure(Map<String, ?> configs) {

        }
    }
```

自定义分区器要实现 Partitioner 接口

> 其中 Partition 方法是最重要的方法, 可以根据不同的数据发送到不同的分区
> 
> close 方法是关闭时候执行的方法一般不做任何操作
> 
> configure 方法是获取配置文件的方法，一般也不做任何操作

思路就是在 partition 方法中得到 value 值中是否包含 spark 或者 java，然后分类发送

整体代码如下：

```
package com.hainiu.kafka;

import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.serialization.StringSerializer;
import org.apache.kafka.common.utils.Utils;

import java.io.FileInputStream;
import java.net.URL;
import java.util.*;

public class ProducerWithUDPartitioner {

    public static class MyTeacherPartitioner implements Partitioner{
        List<String> list = Arrays.asList(
                "unclewang",
                "xiaohe",
                "laoyang",
                "laochen",
                "laoliu",
                "laozhang"
        );
        @Override
        public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
            String valueStr = value.toString();
            return list.indexOf(valueStr);
        }

        @Override
        public void close() {
            //no - op
        }

        @Override
        public void configure(Map<String, ?> configs) {
            // no - op
        }
    }

    public static void main(String[] args) throws Exception{

        Properties pro = new Properties();
        pro.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"nn1:9092");
        pro.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        pro.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        pro.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,MyTeacherPartitioner.class.getName());
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(pro);

        FileInputStream in = new FileInputStream("data/teacher.txt");
        Scanner sc = new Scanner(in);
        while(sc.hasNext()){
            String line = sc.nextLine();
            URL url = new URL(line);
            String host = url.getHost();
            String path = url.getPath();
            String subject = host.split("\\.")[0];
            String teacher = path.substring(1);
            ProducerRecord<String, String> record = new ProducerRecord<>("teacher", subject, teacher);
            producer.send(record, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if(exception == null){
                        System.out.println(metadata.topic()+"-->"+metadata.partition()+"-->"+record.key()+"-->"+record.value());
                    }else{
                        System.out.println("fail");
                    }
                }
            });
        }
        producer.close();
    }
}
```

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230202110503851.png)

数据已经按照规则进行分类

10.kafka 的 ack 和一致性[#](#10.kafka的ack和一致性)
-----------------------------------------

上文中我们提到过 kafka 是存在确认应答机制的，也就是数据在发送到 kafka 的时候，kafka 会回复一个确认信息，这个确认信息是存在等级的

> ack=0 这个等级是最低的，这个级别中数据 sender 线程复制完毕数据默认人为 kafka 已经接收到数据
> 
> ack=1 这个级别中，sender 线程复制完毕数据 leader 分区拿到数据放入到自己的存储并且返回确认信息
> 
> ack= -1 这个级别比较重要，sender 线程复制完毕数据，主分区接受完毕数据并且从分区都同步完毕数据然后在返回确认信息

那么以上的等级在使用的时候都会出现什么问题呢？

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129161301075.png)

ack = 0 会丢失数据

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129161601505.png)

ack=1 的时候 leader 虽然接收到数据存储到本地，但是没有同步给 follower 节点，这个时候主节点宕机，从节点重新选举新的主节点，主节点是不含有这个数据的，数据会丢失

ack = -1

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129162011702.png)

这个模式不会丢失数据，但是如果 leader 接受完毕数据并且将数据同步给不同的 follower，从节点已经接受完毕，但是还没有返回给 sender 线程 ack 的时候，这个时候 leader 节点宕机了，sender 没有接收到这个 ack，它人为没有发送成功还会重新发送数据过来，会造成数据重复

一般前两种都适合在数据并不是特别重要的时候使用，而最后一种效率会比较低下，但是适用于可靠性比较高的场景使用

所以一般使用我们都会使用 ack = -1 retries = N 联合在一起使用

那么我们如何能够保证数据的一致性呢？

**幂等性**

在 kafka 的 0.10 以后的版本中增加了新的特性，幂等性，主要就是为了解决 kafka 的 ack = -1 的时候，数据的重复问题，设计的原理就是在 kafka 中增加一个事物编号

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129163212639.png)

数据在发送的时候在单个分区中的 seq 事物编号是递增的，如果重复的在一个分区中多次插入编号一致的两个信息，那么这个数据会被去重掉

在单个分区中序号递增，也就是我们开启幂等性也只能保证单个分区的数据是可以去重的

整体代码如下：

```
pro.put(ProducerConfig.RETRIES_CONFIG,3);
pro.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,true);
```

设定 retries = 3 ,**enable.idempotence = true**

幂等性开启的时候，ack 默认设定为 - 1

幂等性的工作原理很简单，每条消息都有一个「主键」，这个主键由 <PID, Partition, SeqNumber> 组成，他们分别是：

*   PID：ProducerID，每个生产者启动时，Kafka 都会给它分配一个 ID，ProducerID 是生产者的唯一标识，需要注意的是，Kafka 重启也会重新分配 PID
*   Partition：消息需要发往的分区号
*   SeqNumber：生产者，他会记录自己所发送的消息，给他们分配一个自增的 ID，这个 ID 就是 SeqNumber，是该消息的唯一标识

对于主键相同的数据，Kafka 是不会重复持久化的，它只会接收一条，但由于是原理的限制，幂等性也只能保证单分区、单会话内的数据不重复，如果 Kafka 挂掉，重新给生产者分配了 PID，还是有可能产生重复的数据，这就需要另一个特性来保证了 ——Kafka 事务。

11.kafka 事务原理[#](#11.kafka-事务原理)
--------------------------------

Kafka 事务基于幂等性实现，通过事务机制，Kafka 可以实现对多个 Topic 、多个 Partition 的原子性的写入，即处于同一个事务内的所有消息，最终结果是要么全部写成功，要么全部写失败。

> Kafka 事务分为生产者事务和消费者事务，但它们并不是强绑定的关系，消费者主要依赖自身对事务进行控制，因此这里我们主要讨论的是生产者事务。

### 1. 如何开启事务？[#](#1.-如何开启事务？)

创建一个 Producer，指定一个事务 ID：

```
Properties properties = new Properties();

properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");

properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

//设置事务ID，必须
properties.setProperty(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "transactional_id_1");
//创建生产者
KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
```

使用事务发送消息：

```
// 初始化事务
producer.initTransactions();
// 开启事务
producer.beginTransaction();

//发送10条消息往kafka，假如中间有异常，所有消息都会发送失败
try {
    for (int i = 0; i < 10; i++) {
        producer.send(new ProducerRecord<>("topic-test", "a message" + i));
    }
}
// 提交事务
producer.commitTransaction();
} catch (Exception e) {
    // 终止事务
    producer.abortTransaction();
} finally {
    producer.close();
}
```

### 2. 事务工作原理[#](#2.-事务工作原理)

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129171956526.png)

**1）启动生产者，分配协调器**

在使用事务的时候，必须给生产者指定一个事务 ID，生产者启动时，Kafka 会根据事务 ID 来分配一个**事务协调器（Transaction Coordinator）** 。每个 Broker 都有一个事务协调器，负责分配 **PID（Producer ID）** 和管理事务。

事务协调器的分配涉及到一个特殊的主题 **__transaction_state**，该主题默认有 50 个分区，每个分区负责一部分事务；Kafka 根据`事务ID的hashcode值%50` 计算出该事务属于哪个分区， 该分区 Leader 所在 Broker 的事务协调器就会被分配给该生产者。

分配完事务协调器后，该事务协调器会给生产者分配一个 PID，接下来生产者就可以准备发送消息了。

**2）发送消息**

生产者分配到 PID 后，要先告诉事务协调器要把消息发往哪些分区，协调器会做一个记录，然后生产者就可以开始发送消息了，这些消息与普通的消息不同，它们带着一个字段标识自己是事务消息。

当生产者事务内的消息发送完毕，会向事务协调器发送 Commit 或 Abort 请求，此时生产者的工作已经做完了，它只需要等待 Kafka 的响应。

**3）确认事务**

当生产者开始发送消息时，协调器判定事务开始。它会将开始的信息持久化到主题 `__transaction_state` 中。

当生产者发送完事务内的消息，或者遇到异常发送失败，协调器会收到 Commit 或 Abort 请求，接着事务协调器会跟所有主题通信，告诉它们事务是成功还是失败的。

如果是成功，主题会汇报自己已经收到消息，协调者收到所有主题的回应便确认了事务完成，并持久化这一结果。

如果是失败的，主题会把这个事务内的消息丢弃，并汇报给协调者，协调者收到所有结果后再持久化这一信息，事务结束；整个放弃事务的过程消费者是无感知的，它并不会收到这些数据。

事物不仅可以保证多个数据整体成功失败，还可以保证数据丢失后恢复

### 3. 代码实现[#](#3.代码实现)

```
package com.hainiu.kafka;

import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerWithTransaction {
    public static void main(String[] args) {
        Properties pro = new Properties();
        pro.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"nn1:9092");
        pro.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        pro.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        pro.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,"transaciton_test");

        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(pro);
        ProducerRecord<String, String> record = new ProducerRecord<>("topic_a", "this is hainiu");
        producer.initTransactions();
        producer.beginTransaction();
        try{
            for(int i=0;i<5;i++){
                producer.send(record);
            }
//            int a = 1/0;
            producer.commitTransaction();
        }catch (Exception e){
            producer.abortTransaction();
        }finally {
            producer.close();
        }

    }
}
```

使用 int a = 1/0; 手动抛出异常信息

如果出现异常那么数据不会出现

异常关闭会一次性出现五条结果

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129172647024.png)

12. 一致性语义[#](#12.一致性语义)
-----------------------

在大数据场景中存在三种时间语义，分别为

**At Least Once** 至少一次，数据至少一次，可能会重复

**At Most Once** 至多一次，数据至多一次，可能会丢失

**Exactly Once** 精准一次，有且只有一次，准确的消息传输

那么针对于以上我们学习了 ack 已经幂等性以及事物

所以我们做以下分析：

> 如果设定 ack = 0 或者是 1 出现的语义就是 **At Most Once** 会丢失数据
> 
> 如果设定 ack = - 1 会出现 **At Least Once** 数据的重复
> 
> 在 ack = -1 的基础上开启幂等性会解决掉数据重复问题，但是不能保证一个批次的数据整体一致，所以还要开启事物才可以

13. 参数调节[#](#13.参数调节)
---------------------

<table><thead><tr><th>参数</th><th>调节</th></tr></thead><tbody><tr><td>buffer.memory</td><td>record accumulator 的大小，适当增加可以保证 producer 的速度，默认 32M</td></tr><tr><td>batch-size</td><td>异步线程拉取的批次大小，适当增加可以提高效率，但是会增加延迟性</td></tr><tr><td>linger.ms</td><td>异步线程等待时长一般根据生产效率而定，不建议太大增加延迟效果</td></tr><tr><td>acks</td><td>确认应答一般设定为 - 1，保证数据不丢失</td></tr><tr><td>enable.idempotence</td><td>开启幂等性保证数据去重，实现 exactly once 语义</td></tr><tr><td>retries</td><td>增加重试次数，保证数据的稳定性</td></tr><tr><td>compression.type</td><td>增加 producer 端的压缩</td></tr><tr><td>max.in.flight.requests.per.connection</td><td>sender 线程异步复制数据的阻塞次数，当没收到 kafka 的 ack 之前可以最多发送五个写入请求，调节这个参数可以保证数据的有序性</td></tr></tbody></table>

全部代码如下:

```
package com.hainiu.kafka;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerWithMultiConfig {
    public static void main(String[] args) throws InterruptedException {
        Properties pro = new Properties();
        pro.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"nn1:9092");
        pro.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        pro.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        pro.put(ProducerConfig.BATCH_SIZE_CONFIG, 16*1024);
        pro.put(ProducerConfig.LINGER_MS_CONFIG, 100);
        pro.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 1024*1024*64);
        pro.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
        pro.put(ProducerConfig.RETRIES_CONFIG, 3);
        pro.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");
        pro.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);

        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(pro);
        ProducerRecord<String, String> record = new ProducerRecord<>("topic_a", "this is hainiu");
        producer.send(record);
        producer.close();
    }
}
```

其中 max.in.flight.requests.per.connection 参数设定后可以增加 producer 的阻塞大小

在未开启幂等性的时候，这个值设定为 1，可以保证单个批次的数据有序，在分区内部有序

如果开启了幂等性可以设定最大值不超过 5，可以保证五个 request 请求单个分区内有序

![](http://www.hainiubl.com/uploads/md_images/202302/03/19/image-20230129194432095.png)

因为没有开启幂等性的时候如果第一个请求失败，第二个请求重新发送的时候需要二次排序

要是开启幂等性了会保留原来的顺序性，不需要重新排序

总而言之 kafka 可以保证单分区有序但是整体是无序的

**版权声明: 原创作品, 允许转载，转载时务必以超链接的形式表明出处和作者信息。否则将追究法律责任。来自海汼部落－野牛, http://hainiubl.com/topics/76179**